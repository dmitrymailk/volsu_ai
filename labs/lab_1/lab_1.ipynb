{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Значит задание по 0 лабе: рассчитать индекс удовлетворенности жизнью для [соответствующего датасета из книжки](https://github.com/ageron/handson-ml/tree/master/datasets/lifesat), на основании известных данных ВВП на душу (оттуда же) для не менее 20 точек, не считая известных.\n",
    "\n",
    "- Рассчитывать будете двумя способами:\n",
    "\n",
    "  - методом ближайших соседей\n",
    "  - простой линейной регрессией (одномерной) с двумя коэффициентами\n",
    "\n",
    "\n",
    "- Сделать свои функции для ближайших соседей и регрессии\n",
    "  - для регрессии обязательно провести минимизацию методом наименьших квадратов! (и использовать готовые функции scikit-learn)\n",
    "  - Результаты для ваших и библиотечных методов должны совпадать.\n",
    "  - В методе ближайших соседей посчитать для числа соседей 1 и 3.\n",
    "- Сравнить и сделать выводы. Реализация на языке Python. Не забудьте установить библиотеку scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
    "    oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"] == \"TOT\"]\n",
    "    oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
    "    gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n",
    "    gdp_per_capita.set_index(\"Country\", inplace=True)\n",
    "    full_country_stats = pd.merge(\n",
    "        left=oecd_bli, \n",
    "        right=gdp_per_capita, \n",
    "        left_index=True, \n",
    "        right_index=True\n",
    "    )\n",
    "    \n",
    "    full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n",
    "    remove_indices = [0, 1, 6, 8, 33, 34, 35]\n",
    "    keep_indices = list(set(range(36)) - set(remove_indices))\n",
    "    return full_country_stats.iloc[keep_indices]#[[\"GDP per capita\", \"Life satisfaction\"]]#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Удовлетворенность жизнью и ВВП на душу населения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "oecd_bli = pd.read_csv(\"./datasets/oecd_bli_2015.csv\", thousands=\",\")\n",
    "gdp_per_capita = pd.read_csv(\n",
    "    \"./datasets/gdp_per_capita.csv\",\n",
    "    thousands=\",\",\n",
    "    delimiter=\"\\t\",\n",
    "    encoding=\"latin1\",\n",
    "    na_values=\"n/a\",\n",
    ")\n",
    "\n",
    "\n",
    "# Prepare the data\n",
    "sample_data = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
    "X = np.c_[sample_data[\"GDP per capita\"]]\n",
    "y = np.c_[sample_data[\"Life satisfaction\"]]\n",
    "\n",
    "# Visualize the data\n",
    "sample_data.plot(kind=\"scatter\", x=\"GDP per capita\", y=\"Life satisfaction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29, 1), (29, 1))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Встроенные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression Mean Error = 0.2766686042360626\n",
      "Linear regression Mean Error = 0.27666860423606277\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring=make_scorer(mean_squared_error))\n",
    "scores = scores.mean()\n",
    "print(f\"Linear regression Mean Error = {scores}\")\n",
    "\n",
    "def k_fold_validation(model_class, X, y, cv=5, model_params=None):\n",
    "\tif model_params == None:\n",
    "\t\tmodel_params = {}\n",
    "\t\n",
    "\tk_fold = KFold(n_splits=cv)\n",
    "\tk_fold.get_n_splits(X)\n",
    "\n",
    "\tscores = []\n",
    "\tfor train_index, test_index in k_fold.split(X):\n",
    "\t\tmodel = model_class(**model_params)\n",
    "\t\tX_train, X_test = X[train_index], X[test_index]\n",
    "\t\ty_train, y_test = y[train_index], y[test_index]\n",
    "\t\t# normalize data\n",
    "\t\tscaler = StandardScaler()\n",
    "\t\tscaler.fit(X_train)\n",
    "\t\tX_train = scaler.transform(X_train)\n",
    "\t\tX_test = scaler.transform(X_test)\n",
    "\t\t\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\tpred = model.predict(X_test)\n",
    "\t\tresult = mean_squared_error(y_test, pred)\n",
    "\t\tscores.append(result)\n",
    "\n",
    "\tscores = np.array(scores).mean()\n",
    "\n",
    "\treturn scores\n",
    "\n",
    "scores = k_fold_validation(LinearRegression, X, y, cv=5, model_params=None)\n",
    "print(f\"Linear regression Mean Error = {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model.coef_\n",
    "[[0.61967346]]\n",
    "[[0.67627008]]\n",
    "[[0.70577578]]\n",
    "[[0.76452688]]\n",
    "[[0.39163706]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Mean Error with k_neighbors=1 equals 0.35520000000000007\n",
      "KNN Mean Error with k_neighbors=3 equals 0.2937925925925929\n",
      "KNN Mean Error with k_neighbors=5 equals 0.17607999999999993\n",
      "KNN Mean Error with k_neighbors=7 equals 0.1866897959183674\n",
      "KNN Mean Error with k_neighbors=10 equals 0.2829633333333331\n"
     ]
    }
   ],
   "source": [
    "for k_neighbors in [1, 3, 5, 7, 10]:\n",
    "    scores = k_fold_validation(\n",
    "        model_class=KNeighborsRegressor,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        cv=5,\n",
    "        model_params={\"n_neighbors\": k_neighbors},\n",
    "    )\n",
    "    print(f\"KNN Mean Error with k_neighbors={k_neighbors} equals {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модели с нуля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimweb\\AppData\\Local\\Temp\\ipykernel_15272\\3648896529.py:49: RuntimeWarning: overflow encountered in double_scalars\n",
      "  db = -2 * self.b*(y_batch - Y_pred).sum() / self.m\n",
      "C:\\Users\\dimweb\\AppData\\Local\\Temp\\ipykernel_15272\\3648896529.py:55: RuntimeWarning: invalid value encountered in add\n",
      "  return X @ self.W + self.b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan]])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLinearRegression:\n",
    "    def __init__(self, learning_rate=0.1, iterations=10):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # no_of_training_examples, no_of_features\n",
    "        self.m = X.shape[0]\n",
    "        self.n = X.shape[1]\n",
    "\n",
    "        # weight initialization\n",
    "        self.W = np.ones((self.n, 1))\n",
    "        self.b = 1\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "\n",
    "        # gradient descent learning\n",
    "        for _ in range(self.iterations):\n",
    "            # self.update_weights()\n",
    "            self.update_weights_v2()\n",
    "        print(self.W)\n",
    "\n",
    "    def update_weights(self):\n",
    "\n",
    "        # calculate gradients\n",
    "        Y_pred = self.predict(self.X) / self.m\n",
    "        Y_pred = Y_pred.reshape(self.Y.shape)\n",
    "        # print(Y_pred.shape)\n",
    "        dW = -2 * self.X.T @ (self.Y - Y_pred) / self.m\n",
    "        db = -2 * (self.Y - Y_pred).sum() / self.m\n",
    "        # print(self.W, db)\n",
    "        # print(dW, self.X.T.shape, self.Y.shape, (self.X.T.dot(self.Y - Y_pred)).shape)\n",
    "        # print(db)\n",
    "        self.W -= self.learning_rate * dW\n",
    "        self.b -= self.learning_rate * db\n",
    "\n",
    "    def update_weights_v2(self):\n",
    "        batch_size = 2\n",
    "        for batch in range(len(self.X) // batch_size):\n",
    "            start = batch * batch_size\n",
    "            stop = (batch * batch_size) + batch_size\n",
    "\n",
    "            X_batch = self.X[start:stop]\n",
    "            y_batch = self.y[start:stop]\n",
    "\n",
    "            Y_pred = self.predict(X_batch)\n",
    "            dW = -2 * X_batch.T @ (y_batch - Y_pred) / self.m\n",
    "            db = -2 * self.b*(y_batch - Y_pred).sum() / self.m\n",
    "    \n",
    "            self.W -= self.learning_rate * dW\n",
    "            self.b -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X @ self.W + self.b\n",
    "\n",
    "\n",
    "model = MyLinearRegression(iterations=1, learning_rate=0.0001)\n",
    "model.fit(X, y)\n",
    "model.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.72743273]]\n",
      "[[0.75930128]]\n",
      "[[0.77709863]]\n",
      "[[0.8259135]]\n",
      "[[0.58205059]]\n",
      "1.1748654567186834\n"
     ]
    }
   ],
   "source": [
    "scores = k_fold_validation(\n",
    "    model_class=MyLinearRegression,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=5,\n",
    "    model_params={\n",
    "        \"learning_rate\": 0.01, \n",
    "        \"iterations\": 55\n",
    "    }\n",
    ")\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_x = 3  # The algorithm starts at x=3\n",
    "rate = 0.01  # Learning rate\n",
    "precision = 0.000001  # This tells us when to stop the algorithm\n",
    "previous_step_size = 1  #\n",
    "max_iters = 10000  # maximum number of iterations\n",
    "iters = 0  # iteration counter\n",
    "df = lambda x: 2 * (x + 5)  # Gradient of our function\n",
    "\n",
    "while previous_step_size > precision and iters < max_iters:\n",
    "    prev_x = cur_x  # Store current x value in prev_x\n",
    "    cur_x = cur_x - rate * df(prev_x)  # Grad descent\n",
    "    previous_step_size = abs(cur_x - prev_x)  # Change in x\n",
    "    iters = iters + 1  # iteration count\n",
    "    print(\"Iteration\", iters, \"\\nX value is\", cur_x)  # Print iterations\n",
    "\n",
    "print(\"The local minimum occurs at\", cur_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.87081828e+44]),\n",
       " array([5.19900253e+46, 5.41859602e+46, 7.02770229e+46, 7.17436666e+46,\n",
       "        9.18187362e+46, 9.92618895e+46, 1.03718576e+47, 1.09789232e+47,\n",
       "        1.19038377e+47, 1.48505828e+47, 1.56144937e+47, 1.71483054e+47,\n",
       "        1.86520193e+47, 2.02928590e+47, 2.12698301e+47, 2.16316192e+47,\n",
       "        2.30277705e+47, 2.35387067e+47, 2.40999384e+47, 2.48796372e+47,\n",
       "        2.50353239e+47, 2.51047495e+47, 2.51315383e+47, 2.86313976e+47,\n",
       "        2.91988533e+47, 2.92604507e+47, 2.94837309e+47, 2.99220595e+47,\n",
       "        3.20413200e+47]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.ones(X.shape[1])\n",
    "b = 0\n",
    "\n",
    "reg = lambda x: x @ W + b\n",
    "cost_func = lambda x: (y - reg(x)) ** 2\n",
    "dW_cost_func = lambda x: 2*x.T@(y - reg(x))\n",
    "db_cost_func = lambda x: 2*(y - reg(x))\n",
    "lr = 0.01\n",
    "steps = 5\n",
    "for i in range(steps):\n",
    "\tW -= lr * dW_cost_func(X)\n",
    "\tb -= lr * db_cost_func(X)\n",
    "\n",
    "W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29, 1), (29, 1))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_0 = np.random.rand(29,1)\n",
    "m = np.random.randint(low = 1, high = 20,size = (1,1))  #parametri random tra low e high\n",
    "q = np.random.rand(1)\n",
    "y_0 = (X_0 @ m) + q \n",
    "\n",
    "noise = np.random.randn(y.shape[0], y.shape[1])\n",
    "y = y + noise\n",
    "\n",
    "X_0.shape, y_0.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7151663672154736"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = k_fold_validation(\n",
    "    model_class=MyLinearRegression,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=5,\n",
    "    model_params={\n",
    "        \"learning_rate\": 0.01, \n",
    "        \"iterations\": 16\n",
    "    }\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_derivative(X_batch, y_batch, m_stat):\n",
    "\n",
    "  y_pred = X_batch @ m_stat\n",
    "  n = len(X_batch)\n",
    "\n",
    "  df_dm =  (-2/n) * (X_batch.T @ (y_batch - y_pred))\n",
    "  df_dm = df_dm.reshape(len(df_dm),-1)\n",
    "\n",
    "  return df_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mean_squared_error(X,y,m_stat):\n",
    "  y_pred = X @ m_stat\n",
    "  mse = np.sum(((y_pred - y)**2),axis = 0) / len(X)\n",
    "  \n",
    "  return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, y, batch_size, lr, epochs):\n",
    "  \n",
    "  for epoch in range(epochs):\n",
    "\n",
    "    #random initial statistics\n",
    "    if epoch == 0:\n",
    "      m_stat = np.random.rand(X.shape[1],1)\n",
    "\n",
    "    #shuffle X and y using same permutation\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    #store comulative derivative\n",
    "    cumulative_derivative = np.zeros((X.shape[1],1))\n",
    "\n",
    "    for batch in range(len(X)//batch_size):\n",
    "      start = batch*batch_size\n",
    "      stop = (batch*batch_size) + batch_size\n",
    "\n",
    "      X_batch = X[start:stop]\n",
    "      y_batch = y[start:stop]\n",
    "      \n",
    "      #derivative\n",
    "      cumulative_derivative = cumulative_derivative + partial_derivative(X_batch, y_batch, m_stat)\n",
    "\n",
    "      #updating rule\n",
    "      m_stat = m_stat - (lr*cumulative_derivative)\n",
    "    \n",
    "    print(f\"epoch: {epoch} ----> MSE: {custom_mean_squared_error(X,y,m_stat)}\")\n",
    "      \n",
    "  return m_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 ----> MSE: [2.19965704e+38]\n",
      "epoch: 1 ----> MSE: [8.79607695e+67]\n",
      "epoch: 2 ----> MSE: [2.74976568e+97]\n",
      "epoch: 3 ----> MSE: [1.39853423e+127]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "lr = 0.01\n",
    "epochs = 4\n",
    "\n",
    "m_stat = training(X, y, batch_size, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 ----> MSE: [38.44501756]\n",
      "epoch: 1 ----> MSE: [8.11515413]\n",
      "epoch: 2 ----> MSE: [3.41248788]\n",
      "epoch: 3 ----> MSE: [1.79261385]\n",
      "epoch: 4 ----> MSE: [0.77074466]\n",
      "epoch: 5 ----> MSE: [0.15865555]\n",
      "epoch: 6 ----> MSE: [0.13618797]\n",
      "epoch: 7 ----> MSE: [0.11733463]\n",
      "epoch: 8 ----> MSE: [0.11290029]\n",
      "epoch: 9 ----> MSE: [0.1120361]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "lr = 0.1\n",
    "epochs = 10\n",
    "\n",
    "m_stat = training(X_0,y_0, batch_size,lr,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
