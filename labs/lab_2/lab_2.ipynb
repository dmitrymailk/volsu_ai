{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "# train utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "### Оригинал\n",
    "\n",
    "Добрый день. Следующая вторая лаба - Наивный Байесовский классификатор (на номер не смотрите, это порядковый номер, в котором я делал лабы сам). В качестве датасета используйте Fashion-MNIST (он есть в качестве встроенного в библиотеке scikit-learn, да и в других тоже имеется). Постарайтесь добиться точности хотя бы в 75%, хотя желательно все-таки свыше 80%. Данные крутите, как хотите, но максимальную точность классификации обеспечьте\n",
    "\n",
    "- [доп материал с разьяснениями](./lab_task_materials/Lab_4_ML.docx)\n",
    "\n",
    "### Переделано\n",
    "\n",
    "- Наивный Байесовский классификатор\n",
    "- В качестве датасета используйте Fashion-MNIST\n",
    "- Точность 75%-80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предварительные знания\n",
    "\n",
    "### [Bayes' theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem)\n",
    "\n",
    "P(A | B) = P(B | A)*P(A) / P(B)\n",
    "- P(A | B) is a conditional probability: the probability of event A occurring given that B is true. It is also called the **posterior probability** of A given B.\n",
    "- P(B | A) is also a conditional probability: the probability of event B occurring given that A is true. It can also be interpreted as the **likelihood** of A given a fixed B.\n",
    "- P(A) and P(B) are the probabilities of observing A and B respectively without any given conditions; they are known as the **marginal probability** or **prior probability**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импортируем данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Fashion mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST',\n",
    "    # train = True,\n",
    "    # download = True,\n",
    "    # transform = torchvision.transforms.Compose([\n",
    "    #     torchvision.transforms.ToTensor()                                 \n",
    "    # ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image_data in train_set.data[:3]:\n",
    "\tplt.imshow(image_data, cmap=\"gray\")\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_set.data.numpy()\n",
    "y = train_set.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(X.shape[0], X.shape[1]**2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "scores = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring=make_scorer(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58995\n"
     ]
    }
   ],
   "source": [
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дефолтный результат показывает точность около 58%. Попробуем преобразовать данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_validation(\n",
    "\t\tmodel_class, \n",
    "\t\tX, \n",
    "\t\ty, \n",
    "\t\tcv=5, \n",
    "\t\tmodel_params=None, \n",
    "\t\tmetric=None, \n",
    "\t\tis_norm=True\n",
    "\t):\n",
    "\tassert metric != None, 'Metric should be not a None'\n",
    "\tif model_params == None:\n",
    "\t\tmodel_params = {}\n",
    "\t\n",
    "\tk_fold = KFold(n_splits=cv)\n",
    "\tk_fold.get_n_splits(X)\n",
    "\n",
    "\tscores = []\n",
    "\tfor train_index, test_index in k_fold.split(X):\n",
    "\t\tmodel = model_class(**model_params)\n",
    "\t\tX_train, X_test = X[train_index], X[test_index]\n",
    "\t\ty_train, y_test = y[train_index], y[test_index]\n",
    "\t\t\n",
    "\t\tif is_norm:\n",
    "\t\t\t# normalize data\n",
    "\t\t\tscaler = StandardScaler()\n",
    "\t\t\tscaler.fit(X_train)\n",
    "\t\t\tX_train = scaler.transform(X_train)\n",
    "\t\t\tX_test = scaler.transform(X_test)\n",
    "\t\t\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\tpred = model.predict(X_test)\n",
    "\t\tresult = metric(y_test, pred)\n",
    "\t\tscores.append(result)\n",
    "\n",
    "\tscores = np.array(scores).mean()\n",
    "\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Mean Error = 0.5904666666666667\n"
     ]
    }
   ],
   "source": [
    "scores = k_fold_validation(\n",
    "\tGaussianNB, \n",
    "\tX, \n",
    "\ty, \n",
    "\tcv=5, \n",
    "\tmodel_params=None, \n",
    "\tmetric=accuracy_score,\n",
    "\tis_norm=False\n",
    ")\n",
    "print(f\"GaussianNB Mean Error = {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как Fashion mnist это картинки, то глупо анализировать \"сырые\" данные такой моделью как GaussianNB.\n",
    "Для начала нам необходимо сократить размерность этих данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Mean Error = 0.7778833333333333\n"
     ]
    }
   ],
   "source": [
    "model = lambda : Pipeline([('PCA', PCA(n_components=60)), ('GaussianNB', GaussianNB())])\n",
    "scores = k_fold_validation(\n",
    "\tmodel, \n",
    "\tX, \n",
    "\ty, \n",
    "\tcv=5, \n",
    "\tmodel_params=None, \n",
    "\tmetric=accuracy_score,\n",
    "\tis_norm=False\n",
    ")\n",
    "print(f\"GaussianNB Mean Error = {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить простое сокращение размерности принесло существенный прирост в точности.\n",
    "Теперь попробуем использовать более разумный подход. Попытаемся сформировать выразительные эмбединги при помощи сверточных нейронных сетей, а затем скормить эти эмбединги нашему наивному байесу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor()                                 \n",
    "    ])\n",
    ")\n",
    "dataset_test = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor()                                 \n",
    "    ])\n",
    ")\n",
    "\n",
    "class FashionMNISTDataset(Dataset):\n",
    "    def __init__(self,\n",
    "            transform=None, \n",
    "            target_transform=None,\n",
    "            initial_dataset=None,\n",
    "        ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.initial_dataset = initial_dataset\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        img = self.initial_dataset.data[index].type(torch.float32).reshape(1, 28, 28)\n",
    "        target = self.initial_dataset.targets[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.initial_dataset)\n",
    "\n",
    "train_data = FashionMNISTDataset(initial_dataset=dataset_train)\n",
    "test_data = FashionMNISTDataset(initial_dataset=dataset_test)\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(\n",
    "    train_data, \n",
    "    [50000, 10000], \n",
    "    generator=torch.Generator().manual_seed(228),\n",
    ")\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, )\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import os\n",
    "from importlib.machinery import SourceFileLoader\n",
    "import importlib\n",
    "\n",
    "\n",
    "class BaseExperiment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=None,\n",
    "        dataloader_train=None,\n",
    "        dataloader_valid=None,\n",
    "        dataloader_test=None,\n",
    "        loss_func_class=None,\n",
    "        estimate_func_class=None,\n",
    "        experiment_config=None,\n",
    "        optimizer_class=None,\n",
    "        sheduler_class=None,\n",
    "        project_name=None,\n",
    "        notebook_name=None,\n",
    "        name_run=\"\",\n",
    "        model_description=\"\",\n",
    "    ):\n",
    "        assert (\n",
    "            notebook_name != None\n",
    "        ), f\"notebook_name should be valid filename, but get {notebook_name}\"\n",
    "\n",
    "        # datasets\n",
    "        self.dataloader_train = dataloader_train\n",
    "        self.dataloader_valid = dataloader_valid\n",
    "        self.dataloader_test = dataloader_test\n",
    "\n",
    "        # wandb\n",
    "        self.notebook_name = notebook_name\n",
    "        self.project_name = project_name\n",
    "        self.experiment_config = experiment_config\n",
    "        self.wandb_run = None\n",
    "        self.name_run = name_run\n",
    "        self.model_description = model_description\n",
    "        self.model_name = \"pytorch_model\"\n",
    "        self.model_artifact = None\n",
    "\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.sheduler_class = sheduler_class\n",
    "        self.loss_func_class = loss_func_class\n",
    "        self.estimate_func_class = estimate_func_class\n",
    "\n",
    "        self.model = model\n",
    "        self.optimizer = None\n",
    "        self.sheduler = None\n",
    "        self.loss_func = None\n",
    "        self.estimate_func = None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device {self.device}\")\n",
    "\n",
    "        # prepare for experiment\n",
    "        self.setup()\n",
    "        self.unit_tests()\n",
    "\n",
    "    def setup(self):\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = self.optimizer_class(\n",
    "            self.model.parameters(), **self.experiment_config[\"optimizer\"]\n",
    "        )\n",
    "\n",
    "        if self.sheduler_class != None:\n",
    "            self.sheduler = self.sheduler_class(\n",
    "                self.optimizer, **self.experiment_config[\"sheduler\"]\n",
    "            )\n",
    "\n",
    "        self.loss_func = self.loss_func_class()\n",
    "        self.estimate_func = self.estimate_func_class()\n",
    "\n",
    "        # set model name\n",
    "        date_time = self.get_date()\n",
    "        self.model_name = f\"{self.name_run}---{date_time}.pt\"\n",
    "        self.experiment_config[\"model_name\"] = self.model_name\n",
    "\n",
    "        # setup wandb\n",
    "        # save model structure and weights to wandb\n",
    "        self.model_artifact = wandb.Artifact(\n",
    "            self.name_run,\n",
    "            type=\"model\",\n",
    "            description=self.model_description,\n",
    "            metadata=self.experiment_config,\n",
    "        )\n",
    "\n",
    "    def get_date(self):\n",
    "        now = datetime.now()\n",
    "        date_time = now.strftime(\"%m_%d_%Y__%H_%M_%S\")\n",
    "        return date_time\n",
    "\n",
    "    def unit_tests(self):\n",
    "        # test training\n",
    "        X, y = next(iter(self.dataloader_train))\n",
    "        X, y = X.to(self.device), y.to(self.device)\n",
    "        pred = self.model(X)\n",
    "        loss = self.loss_func(pred, y)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # test valid\n",
    "        X, y = next(iter(self.dataloader_valid))\n",
    "        X, y = X.to(self.device), y.to(self.device)\n",
    "        pred = self.model(X)\n",
    "        test_loss = self.estimate_func(pred, y).item()\n",
    "        correct = (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # initial validation\n",
    "        self.model.eval()\n",
    "        test_loss, correct = 0, 0\n",
    "        num_batches = len(self.dataloader_valid)\n",
    "        size = len(self.dataloader_valid.dataset)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.dataloader_valid:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                pred = self.model(X)\n",
    "                test_loss += self.estimate_func(pred, y).item()\n",
    "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "        print(\"Initial val = \", correct)\n",
    "\n",
    "        print(\"tests ok\")\n",
    "\n",
    "    def train(self):\n",
    "        # https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-artifacts/Pipeline_Versioning_with_W%26B_Artifacts.ipynb#scrollTo=qrAWbBV1rd4I\n",
    "        # если попытаться создать переменную чтобы не городить тут код возникает ошибка с wandb!\n",
    "        with wandb.init(\n",
    "            project=self.project_name,\n",
    "            entity=\"dimweb\",\n",
    "            settings=wandb.Settings(\n",
    "                start_method=\"thread\",\n",
    "                # symlink=False\n",
    "            ),\n",
    "            reinit=True,\n",
    "            name=self.name_run,\n",
    "            config=self.experiment_config,\n",
    "            # sync_tensorboard=True\n",
    "        ) as run:\n",
    "\n",
    "            self.run = run\n",
    "\n",
    "            # save model class\n",
    "            self.save_model_class()\n",
    "\n",
    "            # start train\n",
    "            epochs = self.experiment_config[\"epochs\"]\n",
    "            for i in range(epochs):\n",
    "                print(f\"Epoch: {i}\")\n",
    "                self.train_steps()\n",
    "                self.valid_steps()\n",
    "\n",
    "            # sync model\n",
    "            self.wandb_save_model()\n",
    "\n",
    "            print(f\"train end\")\n",
    "\n",
    "    def save_model_class(self):\n",
    "        # save class\n",
    "        model_class_name = self.experiment_config[\"model_class_name\"]\n",
    "        class_script_path_dest = f\"{os.path.join(wandb.run.dir, model_class_name)}.py\"\n",
    "        class_script_path_src = f\"./models/{model_class_name}.py\"\n",
    "        shutil.copy2(class_script_path_src, class_script_path_dest)\n",
    "        self.model_artifact.add_file(class_script_path_dest)\n",
    "        wandb.save(class_script_path_dest)\n",
    "\n",
    "    def wandb_save_model(self):\n",
    "        # wandb использует symlinks для того чтобы сохранять файлы\n",
    "        # но из-за проблем с правами доступа возникает ошибка и модель нельзя сохранить\n",
    "        # поэтому пришлось сохранять модель в дирректорию с самим запуском\n",
    "        # https://docs.wandb.ai/guides/track/advanced/save-restore#example-of-saving-a-file-to-the-wandb-run-directory\n",
    "        model_save_path = os.path.join(wandb.run.dir, self.model_name)\n",
    "        torch.save(self.model.state_dict(), model_save_path)\n",
    "        self.model_artifact.add_file(model_save_path)\n",
    "        wandb.save(model_save_path)\n",
    "\n",
    "        # save notebook\n",
    "        notebook_path = os.path.join(wandb.run.dir, self.notebook_name)\n",
    "        shutil.copy2(self.notebook_name, notebook_path)\n",
    "        self.model_artifact.add_file(notebook_path)\n",
    "        wandb.save(notebook_path)\n",
    "\n",
    "        wandb.log_artifact(self.model_artifact)\n",
    "\n",
    "    def train_steps(self):\n",
    "        raise NotImplementedError(\"You need specify training steps\")\n",
    "\n",
    "    def valid_steps(self):\n",
    "        raise NotImplementedError(\"You need specify valid steps\")\n",
    "\n",
    "    def load_model(self, artifact_name, additional_model_args={}):\n",
    "        assert artifact_name != \"\"\n",
    "        # for windows subsystem\n",
    "\n",
    "        with wandb.init(project=self.project_name, job_type=\"inference\"):\n",
    "            model_artifact = wandb.use_artifact(artifact_name)\n",
    "            model_dir = model_artifact.download()\n",
    "            model_config = model_artifact.metadata\n",
    "            model_path = os.path.join(model_dir, model_config[\"model_name\"])\n",
    "            # print(model_config)\n",
    "\n",
    "            artifact_name = artifact_name.replace(\":\", \"-\")\n",
    "            model_class_name = model_config[\"model_class_name\"]\n",
    "            model_script_path = f\"./artifacts/{artifact_name}/{model_class_name}.py\"\n",
    "            # get module by path https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path?rq=1\n",
    "            model_class = getattr(\n",
    "                SourceFileLoader(model_class_name, model_script_path).load_module(),\n",
    "                model_class_name,\n",
    "            )\n",
    "\n",
    "            model_args = model_config[\"model_args\"]\n",
    "            model = model_class(**model_args, **additional_model_args)\n",
    "\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            self.model = model\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    @staticmethod\n",
    "    def static_load_model(artifact_name=\"\", project_name=\"\", additional_model_args={}):\n",
    "        assert artifact_name != \"\"\n",
    "        assert project_name != \"\"\n",
    "        with wandb.init(project=project_name, job_type=\"inference\"):\n",
    "            model_artifact = wandb.use_artifact(artifact_name)\n",
    "            model_dir = model_artifact.download()\n",
    "            model_config = model_artifact.metadata\n",
    "            model_path = os.path.join(model_dir, model_config[\"model_name\"])\n",
    "\n",
    "            model_class_name = model_config[\"model_class_name\"]\n",
    "            model_script_path = f\"./artifacts/{artifact_name}/{model_class_name}.py\"\n",
    "            model_class = getattr(\n",
    "                SourceFileLoader(model_class_name, model_script_path).load_module(),\n",
    "                model_class_name,\n",
    "            )\n",
    "\n",
    "            model_args = model_config[\"model_args\"]\n",
    "            model = model_class(**model_args, **additional_model_args)\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model.to(device)\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "            return model\n",
    "\n",
    "    def test(self, artifact_name=\"\", model=None):\n",
    "        raise NotImplementedError(\"You need specify test steps\")\n",
    "\n",
    "\n",
    "class Experiment(BaseExperiment):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Experiment, self).__init__(**kwargs)\n",
    "\n",
    "    def train_steps(self):\n",
    "        self.model.train()\n",
    "        interval = self.experiment_config[\"check_interval\"]\n",
    "\n",
    "        for batch, (X, y) in enumerate(self.dataloader_train):\n",
    "            # Send data to training device\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            pred = self.model(X)\n",
    "            loss = self.loss_func(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if self.sheduler != None:\n",
    "                self.sheduler.step()\n",
    "\n",
    "            # Progress output\n",
    "            if batch % interval == 0:\n",
    "                wandb.log({\"train_loss\": loss.item()})\n",
    "\n",
    "    def valid_steps(self):\n",
    "        self.model.eval()\n",
    "        test_loss, correct = 0, 0\n",
    "        num_batches = len(self.dataloader_valid)\n",
    "        size = len(self.dataloader_valid.dataset)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.dataloader_valid:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                pred = self.model(X)\n",
    "                test_loss += self.estimate_func(pred, y).item()\n",
    "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "\n",
    "        wandb.log({\"val_loss\": test_loss})\n",
    "        wandb.log({\"val_acc\": correct})\n",
    "\n",
    "    def test(self, artifact_name=\"\", model=None):\n",
    "        if model is None:\n",
    "            self.load_model(artifact_name)\n",
    "        else:\n",
    "            self.model = model\n",
    "            self.model.to(self.device)\n",
    "\n",
    "        print(\"model loaded to disk\")\n",
    "        predictions = []\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, _ in self.dataloader_test:\n",
    "                X = X.to(self.device)\n",
    "                pred = self.model(X).argmax(1).cpu().numpy()\n",
    "                predictions.extend(list(pred))\n",
    "\n",
    "        date_time = self.get_date()\n",
    "        filename = f\"./predictions/{self.name_run}---{date_time}.csv\"\n",
    "        with open(filename, \"w\") as solution:\n",
    "            print(\"Id,Category\", file=solution)\n",
    "            for i, label in enumerate(predictions):\n",
    "                print(f\"{i},{label}\", file=solution)\n",
    "        print(\"test end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Initial val =  0.1491\n",
      "tests ok\n"
     ]
    }
   ],
   "source": [
    "def import_class(class_name):\n",
    "    return getattr(importlib.reload(getattr(__import__(f\"models.{class_name}\"), class_name)), class_name)\n",
    "\n",
    "TestModel = import_class(\"TestModel\") \n",
    "\n",
    "\n",
    "exp_config = {\n",
    "    \"batch_size\": 64,\n",
    "    \"check_interval\": 100,\n",
    "    \"epochs\": 1,\n",
    "    \"optimizer\": {\n",
    "        \"lr\": 1e-3\n",
    "    },\n",
    "    \"model_name\": \"pytorch_model\",\n",
    "    \"model_class_name\": str(TestModel.__name__),\n",
    "    \"model_args\": {\n",
    "        \"n_classes\": 10\n",
    "    }\n",
    "}\n",
    "\n",
    "exp_config[\"sheduler\"] = {\n",
    "    \"max_lr\": 0.01, \n",
    "    \"steps_per_epoch\": len(train_dataloader), \n",
    "    \"epochs\": 10\n",
    "}\n",
    "\n",
    "model = TestModel(**exp_config['model_args'])\n",
    "\n",
    "# не хочу создавать глобальные переменные \n",
    "exp_params = {\n",
    "    \"model\": model, \n",
    "    \"dataloader_train\": train_dataloader,\n",
    "    \"dataloader_valid\": val_dataloader,\n",
    "    \"dataloader_test\": test_dataloader,\n",
    "    \"loss_func_class\": nn.CrossEntropyLoss,\n",
    "    \"estimate_func_class\": nn.CrossEntropyLoss,\n",
    "    \"experiment_config\": exp_config,\n",
    "    \"optimizer_class\": torch.optim.Adam,\n",
    "    \"sheduler_class\": torch.optim.lr_scheduler.OneCycleLR,\n",
    "    \"notebook_name\": \"lab_2.ipynb\",\n",
    "    \"project_name\": \"volsu_lab2\",\n",
    "    \"name_run\": \"test_run\",\n",
    "    \"model_description\": \"Test my new model\",\n",
    "}\n",
    "\n",
    "experiment_test = Experiment(**exp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\programming\\volsu\\semester_6\\ai\\labs\\lab_2\\wandb\\run-20220319_162554-2r286gs6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dimweb/volsu_lab2/runs/2r286gs6\" target=\"_blank\">test_run</a></strong> to <a href=\"https://wandb.ai/dimweb/volsu_lab2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train end\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000c52ad9ab2410b91cc479fad084073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.160 MB of 0.160 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>▃▁▁▁▁▂▂▁▁▁▂▂▂▂▂▂▂▂▁▁▄▂▂▃▁▄▂▁▃▂▃▂▁▅█▃▁▂▂▅</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.0</td></tr><tr><td>val_acc</td><td>0.7779</td></tr><tr><td>val_loss</td><td>45.56505</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">test_run</strong>: <a href=\"https://wandb.ai/dimweb/volsu_lab2/runs/2r286gs6\" target=\"_blank\">https://wandb.ai/dimweb/volsu_lab2/runs/2r286gs6</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220319_162554-2r286gs6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_test.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet model\n",
    "\n",
    "Так как наши данные максимально простые, то я предполагаю что нам будет достаточно самой простой модели 90-х годов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⌊(n − k + 2*p + s)/s⌋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8382,  0.2956,  0.2377,  0.5855, -0.0731,  0.3513, -0.2238, -0.1930,\n",
       "         -0.4768, -0.4515],\n",
       "        [-0.5003, -0.4070,  0.1999,  0.6663, -0.0175, -0.1745,  0.1603,  0.3384,\n",
       "         -0.3095,  0.4547]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LeNet5 = import_class(\"LeNet5\") \n",
    "\n",
    "model = LeNet5(10)\n",
    "test_img = torch.rand((2,1, 28, 28))\n",
    "model(test_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Initial val =  0.1292\n",
      "tests ok\n"
     ]
    }
   ],
   "source": [
    "\n",
    "exp_config = {\n",
    "    \"batch_size\": 16,\n",
    "    \"check_interval\": 100,\n",
    "    \"epochs\": 10,\n",
    "    \"optimizer\": {\n",
    "        \"lr\": 1e-3\n",
    "    },\n",
    "    \"model_name\": \"pytorch_model\",\n",
    "    \"model_class_name\": str(LeNet5.__name__),\n",
    "    \"model_args\": {\n",
    "        \"n_classes\": 10\n",
    "    }\n",
    "}\n",
    "\n",
    "exp_config[\"sheduler\"] = {\n",
    "    \"max_lr\": 0.01, \n",
    "    \"steps_per_epoch\": len(train_dataloader), \n",
    "    \"epochs\": 10\n",
    "}\n",
    "\n",
    "model = LeNet5(**exp_config['model_args'])\n",
    "\n",
    "# не хочу создавать глобальные переменные \n",
    "exp_params = {\n",
    "    \"model\": model, \n",
    "    \"dataloader_train\": train_dataloader,\n",
    "    \"dataloader_valid\": val_dataloader,\n",
    "    \"dataloader_test\": test_dataloader,\n",
    "    \"loss_func_class\": nn.CrossEntropyLoss,\n",
    "    \"estimate_func_class\": nn.CrossEntropyLoss,\n",
    "    \"experiment_config\": exp_config,\n",
    "    \"optimizer_class\": torch.optim.Adam,\n",
    "    \"sheduler_class\": torch.optim.lr_scheduler.OneCycleLR,\n",
    "    \"notebook_name\": \"lab_2.ipynb\",\n",
    "    \"project_name\": \"volsu_lab2\",\n",
    "    \"name_run\": \"LeNet5\",\n",
    "    \"model_description\": \"change batch size to 16\",\n",
    "}\n",
    "\n",
    "lenet_exp = Experiment(**exp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\programming\\volsu\\semester_6\\ai\\labs\\lab_2\\wandb\\run-20220319_235937-49jasa9m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dimweb/volsu_lab2/runs/49jasa9m\" target=\"_blank\">LeNet5</a></strong> to <a href=\"https://wandb.ai/dimweb/volsu_lab2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train end\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f047ab5a1e9d4663a9ba1c5bd4d45b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.628 MB of 0.628 MB uploaded (0.001 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>▃▃▄▃▃▄▂▃▃▄▂▂▃▂▃▃█▂▂▂▂▃▃▁▂▁▂▂▄▂▄▃▂▂▂▂▃▁▁▂</td></tr><tr><td>val_acc</td><td>▁▂▂▄▄▆▇███</td></tr><tr><td>val_loss</td><td>██▇▆▆▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.36124</td></tr><tr><td>val_acc</td><td>0.8502</td></tr><tr><td>val_loss</td><td>0.39938</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">LeNet5</strong>: <a href=\"https://wandb.ai/dimweb/volsu_lab2/runs/49jasa9m\" target=\"_blank\">https://wandb.ai/dimweb/volsu_lab2/runs/49jasa9m</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220319_235937-49jasa9m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenet_exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\programming\\volsu\\semester_6\\ai\\labs\\lab_2\\wandb\\run-20220319_174340-1ydjbklv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dimweb/volsu_lab2/runs/1ydjbklv\" target=\"_blank\">vibrant-surf-10</a></strong> to <a href=\"https://wandb.ai/dimweb/volsu_lab2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02975a598a554ddd9ba08d3870244b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vibrant-surf-10</strong>: <a href=\"https://wandb.ai/dimweb/volsu_lab2/runs/1ydjbklv\" target=\"_blank\">https://wandb.ai/dimweb/volsu_lab2/runs/1ydjbklv</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220319_174340-1ydjbklv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded to disk\n",
      "test end\n"
     ]
    }
   ],
   "source": [
    "lenet_exp.test(artifact_name=\"LeNet5:v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оцениваем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenet5 accuracy 0.8481\n"
     ]
    }
   ],
   "source": [
    "predicts = pd.read_csv(\"./predictions/LeNet5---03_19_2022__17_43_50.csv\", index_col=\"Id\")\n",
    "predicts = predicts[['Category']].to_numpy().flatten()\n",
    "# predicts == test_data.\n",
    "ground_truth = dataset_test.targets.numpy()\n",
    "accuracy = (ground_truth == predicts).astype(np.int32).sum() / len(predicts)\n",
    "\n",
    "print(f\"Lenet5 accuracy {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75c218c9925bb57ff8059454943a9629e2d1f68e51994adef3554638d736487b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('volsu_ai': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
